const { lite } = require('../lite');
const config = require('../settings');
const axios = require('axios');
const fs = require('fs');
const path = require('path');
const ffmpeg = require('fluent-ffmpeg');
const { getBuffer } = require('../utils');

// Dossier pour les images g√©n√©r√©es
const AI_IMAGES_DIR = path.join(__dirname, '../database/ai_images');
if (!fs.existsSync(AI_IMAGES_DIR)) {
    fs.mkdirSync(AI_IMAGES_DIR, { recursive: true });
}

// Historique de conversation pour GPT
const conversationHistory = new Map();

module.exports = [
    {
        pattern: "gpt",
        react: "üí¨",
        alias: ["ai", "ask"],
        desc: "Chat avec GPT-4",
        category: "ai",
        filename: __filename,
        async handler(conn, mek, m, { reply, text, sender }) {
            if (!text) return reply("‚ùå Veuillez poser une question apr√®s la commande");
            
            try {
                const userHistory = conversationHistory.get(sender) || [];
                
                // Construire l'historique de conversation
                const messages = [
                    {
                        role: "system",
                        content: "Tu es PATERSON-MD, un assistant IA cr√©√© par Kervens Aubourg. Tu parles fran√ßais et cr√©ole ha√Øtien. Sois concis et utile."
                    },
                    ...userHistory.slice(-6), // Garder les 6 derniers messages
                    { role: "user", content: text }
                ];
                
                const response = await axios.post(
                    'https://api.openai.com/v1/chat/completions',
                    {
                        model: "gpt-4-turbo",
                        messages: messages,
                        temperature: 0.7,
                        max_tokens: 1000
                    },
                    {
                        headers: {
                            'Authorization': `Bearer ${config.OPENAI_KEY}`,
                            'Content-Type': 'application/json'
                        }
                    }
                );
                
                const aiResponse = response.data.choices[0].message.content;
                
                // Mettre √† jour l'historique
                userHistory.push(
                    { role: "user", content: text },
                    { role: "assistant", content: aiResponse }
                );
                conversationHistory.set(sender, userHistory);
                
                reply(`üí¨ GPT-4:\n\n${aiResponse}`);
            } catch (e) {
                console.error("Erreur GPT:", e.response?.data || e.message);
                reply("‚ùå Erreur de l'IA. Veuillez r√©essayer.");
            }
        }
    },
    {
        pattern: "gptgo",
        react: "üîç",
        desc: "GPT avec recherche en temps r√©el",
        category: "ai",
        filename: __filename,
        async handler(conn, mek, m, { reply, text }) {
            if (!text) return reply("‚ùå Veuillez entrer votre requ√™te");
            
            try {
                const searchResponse = await axios.get(
                    `https://api.search.ai/search?query=${encodeURIComponent(text)}`,
                    {
                        headers: { 'Authorization': `Bearer ${config.SEARCH_API_KEY}` }
                    }
                );
                
                const searchData = searchResponse.data.results.slice(0, 3);
                let context = "Contexte de recherche:\n";
                
                searchData.forEach((result, i) => {
                    context += `\n${i+1}. [${result.title}](${result.url})\n${result.snippet}\n`;
                });
                
                const prompt = `${context}\n\nEn utilisant les informations ci-dessus, r√©ponds √† cette question : ${text}`;
                
                const gptResponse = await axios.post(
                    'https://api.openai.com/v1/chat/completions',
                    {
                        model: "gpt-4-turbo",
                        messages: [{ role: "user", content: prompt }],
                        temperature: 0.5,
                        max_tokens: 1500
                    },
                    {
                        headers: {
                            'Authorization': `Bearer ${config.OPENAI_KEY}`,
                            'Content-Type': 'application/json'
                        }
                    }
                );
                
                const aiResponse = gptResponse.data.choices[0].message.content;
                
                let finalResponse = `üîç *R√©ponse avec recherche* üîç\n\n${aiResponse}\n\nüìö Sources:\n`;
                searchData.forEach((result, i) => {
                    finalResponse += `\n${i+1}. [${result.title}](${result.url})`;
                });
                
                reply(finalResponse);
            } catch (e) {
                console.error("Erreur GPT-GO:", e.response?.data || e.message);
                reply("‚ùå Erreur de recherche. Veuillez r√©essayer.");
            }
        }
    },
    {
        pattern: "gemini",
        react: "ü§ñ",
        desc: "Google Gemini Pro",
        category: "ai",
        filename: __filename,
        async handler(conn, mek, m, { reply, text }) {
            if (!text) return reply("‚ùå Veuillez entrer votre requ√™te");
            
            try {
                const response = await axios.post(
                    `https://generativelanguage.googleapis.com/v1beta/models/gemini-pro:generateContent?key=${config.GEMINI_KEY}`,
                    {
                        contents: [{
                            parts: [{
                                text: `Tu es PATERSON-MD, un assistant IA cr√©√© pour la communaut√© ha√Øtienne. R√©ponds en fran√ßais/cr√©ole. Question: ${text}`
                            }]
                        }],
                        generationConfig: {
                            temperature: 0.7,
                            maxOutputTokens: 1000
                        }
                    }
                );
                
                const aiResponse = response.data.candidates[0].content.parts[0].text;
                reply(`ü§ñ Gemini:\n\n${aiResponse}`);
            } catch (e) {
                console.error("Erreur Gemini:", e.response?.data || e.message);
                reply("‚ùå Erreur de Gemini. Veuillez r√©essayer.");
            }
        }
    },
    {
        pattern: "imagine",
        react: "üé®",
        alias: ["genimage", "dalle"],
        desc: "G√©n√©rer une image avec IA",
        category: "ai",
        filename: __filename,
        async handler(conn, mek, m, { reply, text }) {
            if (!text) return reply("‚ùå Veuillez d√©crire l'image √† g√©n√©rer");
            
            try {
                reply("üñåÔ∏è Cr√©ation de votre image...");
                
                const response = await axios.post(
                    'https://api.openai.com/v1/images/generations',
                    {
                        model: "dall-e-3",
                        prompt: text,
                        n: 1,
                        size: "1024x1024",
                        quality: "hd",
                        style: "vivid"
                    },
                    {
                        headers: {
                            'Authorization': `Bearer ${config.OPENAI_KEY}`,
                            'Content-Type': 'application/json'
                        }
                    }
                );
                
                const imageUrl = response.data.data[0].url;
                const revisedPrompt = response.data.data[0].revised_prompt;
                
                const imageBuffer = await getBuffer(imageUrl);
                const filename = `ai_image_${Date.now()}.png`;
                const filePath = path.join(AI_IMAGES_DIR, filename);
                fs.writeFileSync(filePath, imageBuffer);
                
                await conn.sendMessage(
                    m.chat,
                    {
                        image: imageBuffer,
                        caption: `üé® *${text}*\n\n${revisedPrompt}`
                    },
                    { quoted: mek }
                );
            } catch (e) {
                console.error("Erreur DALL-E:", e.response?.data || e.message);
                reply("‚ùå Erreur de g√©n√©ration d'image. Votre prompt peut contenir du contenu bloqu√©.");
            }
        }
    },
    {
        pattern: "flux",
        react: "üåÄ",
        desc: "Assistant IA avanc√© Flux",
        category: "ai",
        filename: __filename,
        async handler(conn, mek, m, { reply, text, sender }) {
            if (!text) return reply("‚ùå Veuillez entrer votre requ√™te");
            
            try {
                const response = await axios.post(
                    'https://api.fluxai.io/v1/chat',
                    {
                        model: "flux-ultra",
                        messages: [
                            {
                                role: "system",
                                content: "Tu es PATERSON-MD, un assistant IA sp√©cialis√© pour Ha√Øti. Utilise un m√©lange de fran√ßais et de cr√©ole ha√Øtien. Sois pr√©cis et utile."
                            },
                            {
                                role: "user",
                                content: text
                            }
                        ],
                        temperature: 0.6
                    },
                    {
                        headers: {
                            'Authorization': `Bearer ${config.FLUX_API_KEY}`,
                            'Content-Type': 'application/json'
                        }
                    }
                );
                
                const aiResponse = response.data.choices[0].message.content;
                reply(`üåÄ Flux AI:\n\n${aiResponse}`);
            } catch (e) {
                console.error("Erreur Flux:", e.response?.data || e.message);
                reply("‚ùå Erreur de l'assistant Flux. Veuillez r√©essayer.");
            }
        }
    },
    {
        pattern: "aimode",
        react: "ü§ñ",
        desc: "Activer/d√©sactiver le mode conversation IA",
        category: "ai",
        filename: __filename,
        async handler(conn, mek, m, { reply, sender }) {
            config.AI_MODE = config.AI_MODE || new Set();
            
            if (config.AI_MODE.has(sender)) {
                config.AI_MODE.delete(sender);
                reply("‚úÖ Mode IA d√©sactiv√©. Je ne r√©pondrai plus automatiquement √† vos messages.");
            } else {
                config.AI_MODE.add(sender);
                reply("ü§ñ Mode IA activ√©! Je r√©pondrai √† tous vos messages comme un assistant IA. Utilisez .aimode pour d√©sactiver.");
            }
        }
    },
    {
        pattern: "resetai",
        react: "üîÑ",
        desc: "R√©initialiser la conversation IA",
        category: "ai",
        filename: __filename,
        async handler(conn, mek, m, { reply, sender }) {
            conversationHistory.delete(sender);
            reply("üîÑ Historique de conversation IA r√©initialis√©. La conversation recommence √† z√©ro.");
        }
    },
    {
        pattern: "tts",
        react: "üó£Ô∏è",
        desc: "Convertir du texte en parole",
        category: "ai",
        filename: __filename,
        async handler(conn, mek, m, { reply, text, args }) {
            if (!text) return reply("‚ùå Veuillez entrer le texte √† convertir");
            
            try {
                const voice = args[1] || "onyx"; // Voix par d√©faut
                const voices = ["alloy", "echo", "fable", "onyx", "nova", "shimmer"];
                
                if (!voices.includes(voice)) {
                    return reply(`‚ùå Voix invalide. Options: ${voices.join(', ')}`);
                }
                
                const response = await axios.post(
                    'https://api.openai.com/v1/audio/speech',
                    {
                        model: "tts-1-hd",
                        input: text,
                        voice: voice
                    },
                    {
                        headers: {
                            'Authorization': `Bearer ${config.OPENAI_KEY}`,
                            'Content-Type': 'application/json'
                        },
                        responseType: 'arraybuffer'
                    }
                );
                
                const audioBuffer = Buffer.from(response.data);
                const tmpPath = path.join(AI_IMAGES_DIR, `tts_${Date.now()}.mp3`);
                fs.writeFileSync(tmpPath, audioBuffer);
                
                await conn.sendMessage(
                    m.chat,
                    {
                        audio: fs.readFileSync(tmpPath),
                        mimetype: 'audio/mpeg',
                        fileName: 'message_tts.mp3'
                    },
                    { quoted: mek }
                );
                
                fs.unlinkSync(tmpPath);
            } catch (e) {
                console.error("Erreur TTS:", e.response?.data || e.message);
                reply("‚ùå Erreur de synth√®se vocale. Veuillez r√©essayer.");
            }
        }
    },
    {
        pattern: "stt",
        react: "üìù",
        desc: "Convertir un message vocal en texte",
        category: "ai",
        filename: __filename,
        async handler(conn, mek, m, { reply, quoted }) {
            if (!quoted || !quoted.message.audioMessage) {
                return reply("‚ùå R√©pondez √† un message vocal");
            }
            
            try {
                const audioBuffer = await conn.downloadMediaMessage(quoted);
                const tmpPath = path.join(AI_IMAGES_DIR, `stt_${Date.now()}.ogg`);
                fs.writeFileSync(tmpPath, audioBuffer);
                
                // Convertir en MP3 si n√©cessaire
                const mp3Path = path.join(AI_IMAGES_DIR, `stt_${Date.now()}.mp3`);
                await new Promise((resolve, reject) => {
                    ffmpeg(tmpPath)
                        .toFormat('mp3')
                        .save(mp3Path)
                        .on('end', resolve)
                        .on('error', reject);
                });
                
                const audioFile = fs.createReadStream(mp3Path);
                const form = new FormData();
                form.append('file', audioFile, 'audio.mp3');
                form.append('model', 'whisper-1');
                
                const response = await axios.post(
                    'https://api.openai.com/v1/audio/transcriptions',
                    form,
                    {
                        headers: {
                            'Authorization': `Bearer ${config.OPENAI_KEY}`,
                            ...form.getHeaders()
                        }
                    }
                );
                
                const transcription = response.data.text;
                reply(`üìù Transcription:\n\n${transcription}`);
                
                // Nettoyer les fichiers temporaires
                fs.unlinkSync(tmpPath);
                fs.unlinkSync(mp3Path);
            } catch (e) {
                console.error("Erreur STT:", e.response?.data || e.message);
                reply("‚ùå Erreur de reconnaissance vocale. Veuillez r√©essayer.");
            }
        }
    },
    {
        pattern: "vision",
        react: "üëÅÔ∏è",
        desc: "D√©crire une image avec IA",
        category: "ai",
        filename: __filename,
        async handler(conn, mek, m, { reply, quoted, text }) {
            if (!quoted || !quoted.message.imageMessage) {
                return reply("‚ùå R√©pondez √† une image");
            }
            
            try {
                const prompt = text || "Que vois-tu sur cette image? D√©cris en d√©tail.";
                const imageBuffer = await conn.downloadMediaMessage(quoted);
                const base64Image = imageBuffer.toString('base64');
                
                const response = await axios.post(
                    'https://api.openai.com/v1/chat/completions',
                    {
                        model: "gpt-4-vision-preview",
                        messages: [
                            {
                                role: "user",
                                content: [
                                    { type: "text", text: prompt },
                                    {
                                        type: "image_url",
                                        image_url: {
                                            url: `data:image/jpeg;base64,${base64Image}`
                                        }
                                    }
                                ]
                            }
                        ],
                        max_tokens: 1000
                    },
                    {
                        headers: {
                            'Authorization': `Bearer ${config.OPENAI_KEY}`,
                            'Content-Type': 'application/json'
                        }
                    }
                );
                
                const aiResponse = response.data.choices[0].message.content;
                reply(`üëÅÔ∏è Vision IA:\n\n${aiResponse}`);
            } catch (e) {
                console.error("Erreur Vision:", e.response?.data || e.message);
                reply("‚ùå Erreur d'analyse d'image. Veuillez r√©essayer.");
            }
        }
    },
    {
        pattern: "haiai",
        react: "üá≠üáπ",
        desc: "Assistant IA sp√©cialis√© sur Ha√Øti",
        category: "ai",
        filename: __filename,
        async handler(conn, mek, m, { reply, text }) {
            if (!text) return reply("‚ùå Veuillez poser votre question sur Ha√Øti");
            
            try {
                const response = await axios.post(
                    'https://api.openai.com/v1/chat/completions',
                    {
                        model: "gpt-4-turbo",
                        messages: [
                            {
                                role: "system",
                                content: `Tu es un expert sur Ha√Øti. Tu connais la culture, l'histoire, la g√©ographie et l'actualit√© ha√Øtienne. 
                                R√©ponds en cr√©ole ha√Øtien ou en fran√ßais selon la pr√©f√©rence de l'utilisateur. 
                                Date actuelle: ${new Date().toLocaleDateString()}.`
                            },
                            {
                                role: "user",
                                content: text
                            }
                        ],
                        temperature: 0.7,
                        max_tokens: 1000
                    },
                    {
                        headers: {
                            'Authorization': `Bearer ${config.OPENAI_KEY}`,
                            'Content-Type': 'application/json'
                        }
                    }
                );
                
                const aiResponse = response.data.choices[0].message.content;
                reply(`üá≠üáπ Assistant Ha√Øti:\n\n${aiResponse}`);
            } catch (e) {
                console.error("Erreur Haiti AI:", e.response?.data || e.message);
                reply("‚ùå Erreur de l'assistant Ha√Øti. Veuillez r√©essayer.");
            }
        }
    },
    {
        pattern: "docai",
        react: "üìÑ",
        desc: "Analyser un document avec IA",
        category: "ai",
        filename: __filename,
        async handler(conn, mek, m, { reply, quoted, text }) {
            if (!quoted || !quoted.message.documentMessage) {
                return reply("‚ùå R√©pondez √† un document (PDF, DOCX, TXT)");
            }
     
